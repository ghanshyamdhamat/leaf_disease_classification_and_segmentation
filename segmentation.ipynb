{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import skimage as ski\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from skimage import transform as ski_transform\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, RandomRotation\n",
    "from torchvision import models\n",
    "import torchvision.transforms.functional as FT\n",
    "from torcheval.metrics import functional as FM\n",
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    RandomRotation(10),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def joint_random_rotation(image, label, degrees):\n",
    "    # Get a random angle from the range [-degrees, degrees]\n",
    "    angle = RandomRotation.get_params([-degrees, degrees])\n",
    "    \n",
    "    # Rotate the image using bilinear interpolation\n",
    "    image = FT.rotate(image, angle, interpolation=Image.BILINEAR)\n",
    "    \n",
    "    # Rotate the label using nearest neighbor to avoid interpolating label values\n",
    "    label = FT.rotate(label, angle, interpolation=Image.NEAREST)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def joint_random_horizontal_flip(image, label):\n",
    "    if torch.rand(1) < 0.5:\n",
    "        image = FT.hflip(image)\n",
    "        label = FT.hflip(label)\n",
    "    return image, label\n",
    "\n",
    "def joint_random_vertical_flip(image, label):\n",
    "    if torch.rand(1) < 0.5:\n",
    "        image = FT.vflip(image)\n",
    "        label = FT.vflip(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def joint_random_crop(image, label, output_size):\n",
    "    # Get the size of the image\n",
    "    w, h = image.size\n",
    "\n",
    "    # Get the target size\n",
    "    th, tw = output_size\n",
    "\n",
    "    # Randomly crop the image\n",
    "    i = torch.randint(0, h - th + 1, (1,))\n",
    "    j = torch.randint(0, w - tw + 1, (1,))\n",
    "    image = FT.crop(image, i.item(), j.item(), th, tw)\n",
    "    \n",
    "    # Crop the label using the same parameters\n",
    "    label = FT.crop(label, i.item(), j.item(), th, tw)\n",
    "\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x75e65055b6f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 60\n",
    "LEARNING_RATE = [0.0001]#,0.0001,0.00001]\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "RESIZE_DIM = (256, 256)\n",
    "repeats = 3\n",
    "val_step = 3 # Every 3 epoch carry out validation\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide training path and test_path\n",
    "train_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/Dataset/train'\n",
    "test_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/Dataset/test'\n",
    "\n",
    "train_csv_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/train.csv'\n",
    "test_csv_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>binary_pred</th>\n",
       "      <th>segmentation_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>1</td>\n",
       "      <td>27797 2 28053 4 28063 2 28309 15 28565 19 2882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3629 4 3883 8 4137 12 4390 17 4644 21 4898 25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.png</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.png</td>\n",
       "      <td>1</td>\n",
       "      <td>19931 7 20187 10 20443 10 20699 10 20955 10 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101.png</td>\n",
       "      <td>1</td>\n",
       "      <td>6392 4 6645 7 6899 9 7150 15 7394 27 7645 32 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102.png</td>\n",
       "      <td>1</td>\n",
       "      <td>8475 1 8730 4 8986 5 9242 6 9498 7 9754 9 1001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103.png</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104.png</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105.png</td>\n",
       "      <td>1</td>\n",
       "      <td>17528 1 17781 5 17846 1 18034 9 18102 2 18287 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106.png</td>\n",
       "      <td>1</td>\n",
       "      <td>23612 5 23866 9 24121 9 24377 6 29270 25 29524...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  binary_pred                                  segmentation_pred\n",
       "0      0.png            1  27797 2 28053 4 28063 2 28309 15 28565 19 2882...\n",
       "1      1.png            1  3629 4 3883 8 4137 12 4390 17 4644 21 4898 25 ...\n",
       "10    10.png            0                                            Healthy\n",
       "100  100.png            1  19931 7 20187 10 20443 10 20699 10 20955 10 21...\n",
       "101  101.png            1  6392 4 6645 7 6899 9 7150 15 7394 27 7645 32 7...\n",
       "102  102.png            1  8475 1 8730 4 8986 5 9242 6 9498 7 9754 9 1001...\n",
       "103  103.png            0                                            Healthy\n",
       "104  104.png            0                                            Healthy\n",
       "105  105.png            1  17528 1 17781 5 17846 1 18034 9 18102 2 18287 ...\n",
       "106  106.png            1  23612 5 23866 9 24121 9 24377 6 29270 25 29524..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "id : Name of the image\n",
    "Binary prediction\n",
    "    Healthy = 0\n",
    "    Diseased = 1\n",
    "segmentation prediction\n",
    "    Probably the id of the diseased pixel\n",
    "\"\"\"\n",
    "train_csv_data = pd.read_csv(train_csv_path)\n",
    "#Sort train_csv_data by id\n",
    "train_csv_data = train_csv_data.sort_values(by='id')\n",
    "train_csv_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, masks, labels, is_train= True, resize_dim = (224, 224)):\n",
    "        self.resize_dim = resize_dim\n",
    "        self.images = images\n",
    "        self.is_train = is_train\n",
    "        self.image_transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.label_transform = ToTensor()\n",
    "        if is_train:\n",
    "            self.masks = masks\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            self.masks = None\n",
    "            self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.images):\n",
    "            print('Reduce the index count as it is greater than the length of the dataset')\n",
    "            return None\n",
    "        if idx < 0:\n",
    "            print('Index should be greater than or equal to 0')\n",
    "            return None\n",
    "        data = {}\n",
    "\n",
    "        if self.is_train:\n",
    "            data['image'] = Image.open(self.images[idx])\n",
    "            data['mask'] = Image.open(self.masks[idx])\n",
    "            data['class_label'] = self.labels.iloc[idx, 1]\n",
    "            data['id'] = self.images[idx].split('/')[-1]\n",
    "            data['image'], data['mask'] = joint_random_rotation(data['image'], data['mask'], 10)\n",
    "            data['image'], data['mask'] = joint_random_horizontal_flip(data['image'], data['mask'])\n",
    "            data['image'], data['mask'] = joint_random_vertical_flip(data['image'], data['mask'])\n",
    "            data['image'], data['mask'] = joint_random_crop(data['image'], data['mask'], self.resize_dim)\n",
    "            data['image'] = data['image'].resize(self.resize_dim)\n",
    "            data['mask'] = data['mask'].resize(self.resize_dim)\n",
    "            data['class_label'] = torch.tensor(data['class_label']).float()\n",
    "            if self.image_transform:\n",
    "                data['image'] = self.image_transform(data['image']) \n",
    "                data['mask'] = self.label_transform(data['mask'])\n",
    "            return data\n",
    "        else:\n",
    "            data['image'] = Image.open(self.images[idx])\n",
    "            data['id'] = self.images[idx].split('/')[-1]\n",
    "            if self.image_transform:\n",
    "                data['image'] = self.image_transform(data['image'])\n",
    "            return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the images in val and train from train_path\n",
    "def create_k_fold_split(train_path, train_csv_path):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    train_img_paths = glob(os.path.join(train_path, 'images', '*.png'))\n",
    "    train_img_paths.sort()\n",
    "    train_mask_paths = glob(os.path.join(train_path, 'masks', '*.png'))\n",
    "    train_mask_paths.sort() \n",
    "    train_labels = pd.read_csv(train_csv_path)\n",
    "    train_labels = train_labels.sort_values(by='id')\n",
    "    train_labels.index = range(len(train_labels))\n",
    "    split = list(kf.split(train_img_paths))\n",
    "    return split, train_img_paths, train_mask_paths, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(train_img_paths, train_mask_paths, train_labels, val_img_paths, val_mask_paths, val_labels):\n",
    "    train_dataset = CustomDataset(train_img_paths, train_mask_paths, train_labels, is_train=True, resize_dim=RESIZE_DIM)\n",
    "    val_dataset = CustomDataset(val_img_paths, val_mask_paths, val_labels, is_train=True, resize_dim=RESIZE_DIM)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def get_dataloader(train_dataset, val_dataset, batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def get_splitted_data(train_indices, val_indices):\n",
    "    train = [train_img_paths[i] for i in train_indices]\n",
    "    train_masks = [train_mask_paths[i] for i in train_indices]\n",
    "    training_labels = train_labels.iloc[train_indices]\n",
    "    val = [train_img_paths[i] for i in val_indices]\n",
    "    val_masks = [train_mask_paths[i] for i in val_indices]\n",
    "    val_labels = train_labels.iloc[val_indices]\n",
    "    return train, train_masks, training_labels, val, val_masks, val_labels\n",
    "\n",
    "split, train_img_paths, train_mask_paths, train_labels = create_k_fold_split(train_path, train_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model Segformer for fold 1...\n",
      "Epoch [1/60], Train Loss: 0.5718, Train Dice Score: 0.4461, Train F1 score: 0.4232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/biomedialab/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/60], Train Loss: 0.4516, Train Dice Score: 0.4997, Train F1 score: 0.5607\n",
      "Epoch [3/60], Train Loss: 0.3931, Train Dice Score: 0.5962, Train F1 score: 0.6165\n",
      "\n",
      " Validation Loss: 0.3090, Validation Dice Score: 0.7592, Validation f1 score: 0.6926\n",
      "Model saved to /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Best model updated at epoch 3 with val loss: 0.3090\n",
      "Epoch [4/60], Train Loss: 0.3512, Train Dice Score: 0.6315, Train F1 score: 0.6539\n",
      "Epoch [5/60], Train Loss: 0.3490, Train Dice Score: 0.6327, Train F1 score: 0.6443\n",
      "Epoch [6/60], Train Loss: 0.3340, Train Dice Score: 0.6580, Train F1 score: 0.6720\n",
      "\n",
      " Validation Loss: 0.2856, Validation Dice Score: 0.7445, Validation f1 score: 0.7023\n",
      "Model saved to /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Best model updated at epoch 6 with val loss: 0.2856\n",
      "Epoch [7/60], Train Loss: 0.3017, Train Dice Score: 0.6675, Train F1 score: 0.6954\n",
      "Epoch [8/60], Train Loss: 0.2862, Train Dice Score: 0.7305, Train F1 score: 0.7033\n",
      "Epoch [9/60], Train Loss: 0.2871, Train Dice Score: 0.6962, Train F1 score: 0.7130\n",
      "\n",
      " Validation Loss: 0.2775, Validation Dice Score: 0.7337, Validation f1 score: 0.7091\n",
      "Model saved to /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Best model updated at epoch 9 with val loss: 0.2775\n",
      "Epoch [10/60], Train Loss: 0.2954, Train Dice Score: 0.7159, Train F1 score: 0.7059\n",
      "Epoch [11/60], Train Loss: 0.2846, Train Dice Score: 0.7303, Train F1 score: 0.7149\n",
      "Epoch [12/60], Train Loss: 0.2530, Train Dice Score: 0.7108, Train F1 score: 0.7250\n",
      "\n",
      " Validation Loss: 0.2595, Validation Dice Score: 0.7497, Validation f1 score: 0.7233\n",
      "Model saved to /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Best model updated at epoch 12 with val loss: 0.2595\n",
      "Epoch [13/60], Train Loss: 0.2327, Train Dice Score: 0.7485, Train F1 score: 0.7461\n",
      "Epoch [14/60], Train Loss: 0.2625, Train Dice Score: 0.7377, Train F1 score: 0.7161\n",
      "Epoch [15/60], Train Loss: 0.2550, Train Dice Score: 0.7479, Train F1 score: 0.7429\n",
      "\n",
      " Validation Loss: 0.3218, Validation Dice Score: 0.7352, Validation f1 score: 0.6601\n",
      "Epoch [16/60], Train Loss: 0.2381, Train Dice Score: 0.7333, Train F1 score: 0.7396\n",
      "Epoch [17/60], Train Loss: 0.2184, Train Dice Score: 0.7793, Train F1 score: 0.7790\n",
      "Epoch [18/60], Train Loss: 0.2192, Train Dice Score: 0.7791, Train F1 score: 0.7709\n",
      "\n",
      " Validation Loss: 0.2541, Validation Dice Score: 0.7996, Validation f1 score: 0.7258\n",
      "Model saved to /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Best model updated at epoch 18 with val loss: 0.2541\n",
      "Epoch [19/60], Train Loss: 0.2303, Train Dice Score: 0.7850, Train F1 score: 0.7662\n",
      "Epoch [20/60], Train Loss: 0.2197, Train Dice Score: 0.7715, Train F1 score: 0.7767\n",
      "Epoch [21/60], Train Loss: 0.2158, Train Dice Score: 0.8083, Train F1 score: 0.7797\n",
      "\n",
      " Validation Loss: 0.2434, Validation Dice Score: 0.8078, Validation f1 score: 0.7365\n",
      "Model saved to /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Best model updated at epoch 21 with val loss: 0.2434\n",
      "Epoch [22/60], Train Loss: 0.1890, Train Dice Score: 0.7934, Train F1 score: 0.7858\n",
      "Epoch [23/60], Train Loss: 0.1834, Train Dice Score: 0.8095, Train F1 score: 0.7781\n",
      "Epoch [24/60], Train Loss: 0.1792, Train Dice Score: 0.8214, Train F1 score: 0.8012\n",
      "\n",
      " Validation Loss: 0.2264, Validation Dice Score: 0.8031, Validation f1 score: 0.7543\n",
      "Model saved to /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Best model updated at epoch 24 with val loss: 0.2264\n",
      "Epoch [25/60], Train Loss: 0.1818, Train Dice Score: 0.8229, Train F1 score: 0.8052\n",
      "Epoch [26/60], Train Loss: 0.2098, Train Dice Score: 0.7936, Train F1 score: 0.7779\n",
      "Epoch [27/60], Train Loss: 0.1953, Train Dice Score: 0.7847, Train F1 score: 0.7989\n",
      "\n",
      " Validation Loss: 0.2419, Validation Dice Score: 0.7991, Validation f1 score: 0.7369\n",
      "Epoch [28/60], Train Loss: 0.1856, Train Dice Score: 0.7983, Train F1 score: 0.7815\n",
      "Epoch [29/60], Train Loss: 0.1980, Train Dice Score: 0.7858, Train F1 score: 0.7758\n",
      "Epoch [30/60], Train Loss: 0.1766, Train Dice Score: 0.8045, Train F1 score: 0.7901\n",
      "\n",
      " Validation Loss: 0.2355, Validation Dice Score: 0.7278, Validation f1 score: 0.7453\n",
      "Epoch [31/60], Train Loss: 0.1682, Train Dice Score: 0.8232, Train F1 score: 0.8178\n",
      "Epoch [32/60], Train Loss: 0.1765, Train Dice Score: 0.8205, Train F1 score: 0.7974\n",
      "Epoch [33/60], Train Loss: 0.1947, Train Dice Score: 0.8344, Train F1 score: 0.7979\n",
      "\n",
      " Validation Loss: 0.2657, Validation Dice Score: 0.7530, Validation f1 score: 0.7144\n",
      "Epoch [34/60], Train Loss: 0.1952, Train Dice Score: 0.8132, Train F1 score: 0.8044\n",
      "Epoch [35/60], Train Loss: 0.1804, Train Dice Score: 0.8396, Train F1 score: 0.8117\n",
      "Epoch [36/60], Train Loss: 0.1825, Train Dice Score: 0.8370, Train F1 score: 0.8033\n",
      "\n",
      " Validation Loss: 0.2511, Validation Dice Score: 0.8031, Validation f1 score: 0.7244\n",
      "Epoch [37/60], Train Loss: 0.1635, Train Dice Score: 0.8446, Train F1 score: 0.8287\n",
      "Epoch [38/60], Train Loss: 0.1618, Train Dice Score: 0.8288, Train F1 score: 0.8179\n",
      "Epoch [39/60], Train Loss: 0.2137, Train Dice Score: 0.7879, Train F1 score: 0.7726\n",
      "\n",
      " Validation Loss: 0.2460, Validation Dice Score: 0.7491, Validation f1 score: 0.7340\n",
      "Epoch [40/60], Train Loss: 0.1732, Train Dice Score: 0.8123, Train F1 score: 0.7987\n",
      "Epoch [41/60], Train Loss: 0.1766, Train Dice Score: 0.8212, Train F1 score: 0.7954\n",
      "Epoch [42/60], Train Loss: 0.1551, Train Dice Score: 0.8377, Train F1 score: 0.8169\n",
      "\n",
      " Validation Loss: 0.2280, Validation Dice Score: 0.7981, Validation f1 score: 0.7513\n",
      "Epoch [43/60], Train Loss: 0.1796, Train Dice Score: 0.8153, Train F1 score: 0.8126\n",
      "Epoch [44/60], Train Loss: 0.1674, Train Dice Score: 0.8145, Train F1 score: 0.7984\n",
      "Epoch [45/60], Train Loss: 0.1921, Train Dice Score: 0.7815, Train F1 score: 0.7875\n",
      "\n",
      " Validation Loss: 0.2440, Validation Dice Score: 0.8010, Validation f1 score: 0.7339\n",
      "Epoch [46/60], Train Loss: 0.1623, Train Dice Score: 0.8428, Train F1 score: 0.8299\n",
      "Epoch [47/60], Train Loss: 0.1537, Train Dice Score: 0.8484, Train F1 score: 0.8309\n",
      "Epoch [48/60], Train Loss: 0.1455, Train Dice Score: 0.8644, Train F1 score: 0.8454\n",
      "\n",
      " Validation Loss: 0.2537, Validation Dice Score: 0.7694, Validation f1 score: 0.7226\n",
      "Epoch [49/60], Train Loss: 0.1425, Train Dice Score: 0.8338, Train F1 score: 0.8226\n",
      "Epoch [50/60], Train Loss: 0.1597, Train Dice Score: 0.8460, Train F1 score: 0.8324\n",
      "Epoch [51/60], Train Loss: 0.1897, Train Dice Score: 0.8052, Train F1 score: 0.7957\n",
      "\n",
      " Validation Loss: 0.2326, Validation Dice Score: 0.7788, Validation f1 score: 0.7489\n",
      "Epoch [52/60], Train Loss: 0.1537, Train Dice Score: 0.8385, Train F1 score: 0.8118\n",
      "Epoch [53/60], Train Loss: 0.1600, Train Dice Score: 0.8476, Train F1 score: 0.8117\n",
      "Epoch [54/60], Train Loss: 0.1784, Train Dice Score: 0.8233, Train F1 score: 0.8069\n",
      "\n",
      " Validation Loss: 0.2266, Validation Dice Score: 0.8002, Validation f1 score: 0.7532\n",
      "Epoch [55/60], Train Loss: 0.1582, Train Dice Score: 0.8269, Train F1 score: 0.8128\n",
      "Epoch [56/60], Train Loss: 0.1518, Train Dice Score: 0.8582, Train F1 score: 0.8329\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 213\u001b[0m\n\u001b[1;32m    201\u001b[0m model\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m    203\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    204\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    205\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m     fold_number\u001b[38;5;241m=\u001b[39mfold_number,\n\u001b[1;32m    211\u001b[0m )\n\u001b[0;32m--> 213\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(num_epochs\u001b[38;5;241m=\u001b[39mEPOCHS)\n",
      "Cell \u001b[0;32mIn[29], line 95\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     93\u001b[0m label \u001b[38;5;241m=\u001b[39m label[:, \u001b[38;5;241m0\u001b[39m, :, :] \u001b[38;5;66;03m# Select the first channel\u001b[39;00m\n\u001b[1;32m     94\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Add a channel dimension\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m output_seg, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(image, label) \n\u001b[1;32m     96\u001b[0m output_seg \u001b[38;5;241m=\u001b[39m output_seg[:, \u001b[38;5;241m0\u001b[39m, :, :] \u001b[38;5;66;03m# Select the first channel\u001b[39;00m\n\u001b[1;32m     97\u001b[0m output_seg \u001b[38;5;241m=\u001b[39m output_seg\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Add a channel dimension     \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 126\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m    124\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_dice_score(preds, targets):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        preds: Binary prediction mask (B, C, H, W)\n",
    "        targets: Binary target mask (B, C, H, W)\n",
    "    Returns:\n",
    "        Mean Dice score across batch and channels\n",
    "    \"\"\"\n",
    "    dices = []\n",
    "    smooth = 1e-6\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > 0.5).float()\n",
    "    for i in range(targets.size(0)):\n",
    "        pred_flat = preds[i].reshape(-1)\n",
    "        target_flat = targets[i,0].reshape(-1)\n",
    "        intersection = torch.sum(pred_flat * target_flat)\n",
    "        if torch.sum(pred_flat) == 0 and torch.sum(target_flat) == 0:\n",
    "            dices.append(1.0)\n",
    "        elif torch.sum(pred_flat) == 0 or torch.sum(target_flat) == 0:\n",
    "            dices.append(0.0)\n",
    "        else:\n",
    "            dices.append((2. * intersection + smooth) / (torch.sum(pred_flat) + torch.sum(target_flat) + smooth))\n",
    "    return torch.mean(torch.tensor(dices)).item()\n",
    "\n",
    "def calculate_f1_score(preds, targets):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        preds: Binary prediction mask (B, C, H, W)\n",
    "        targets: Binary target mask (B, C, H, W)\n",
    "    Returns:\n",
    "        Mean accuracy across batch and channels\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > 0.5).float()\n",
    "    preds = preds.reshape(-1)\n",
    "    targets = targets.reshape(-1)\n",
    "    tp = torch.sum(preds * targets)\n",
    "    fp = torch.sum(preds) - tp\n",
    "    fn = torch.sum(targets) - tp\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    return f1_score.item(), precision.item(), recall.item()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler=None, model_name=None,lr = 0.001, fold_number=None):\n",
    "\n",
    "        self.scheduler = scheduler\n",
    "        self.hyperparameters = {\n",
    "            'model_name': model_name,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': lr,\n",
    "            'epochs': EPOCHS,\n",
    "            'val_step': val_step,\n",
    "            'seed': seed,\n",
    "            'fold_number': fold_number,\n",
    "        }\n",
    "        self.model = model\n",
    "        self.criterion = smp.losses.DiceLoss(mode='binary', from_logits=True , smooth=1e-7)\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.best_model_seg = None\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.results = {\n",
    "            'train_loss': [],\n",
    "            'train_dice_score': [],\n",
    "            'train_precision': [],\n",
    "            'train_recall': [],\n",
    "            'train_f1_score': [],\n",
    "            'val_loss': [],\n",
    "            'val_dice_score': [],\n",
    "            'val_f1_score': [],\n",
    "            'val_precision': [],\n",
    "            'val_recall': [],\n",
    "        }\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            output_seg = None\n",
    "            dice_score = 0\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            f1_score = 0\n",
    "            val_loss_for_epoch = 0\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "                image = data['image'].float().to(DEVICE)\n",
    "                label = data['mask'].float().to(DEVICE)\n",
    "                label = label[:, 0, :, :] # Select the first channel\n",
    "                label = label.unsqueeze(1) # Add a channel dimension\n",
    "                output_seg, loss = self.train_step(image, label) \n",
    "                output_seg = output_seg[:, 0, :, :] # Select the first channel\n",
    "                output_seg = output_seg.unsqueeze(1) # Add a channel dimension     \n",
    "                train_loss += loss\n",
    "                dice_score += calculate_dice_score(output_seg, label)\n",
    "                tuple = calculate_f1_score(output_seg, label)\n",
    "                f1_score += tuple[0]\n",
    "                precision += tuple[1]\n",
    "                recall += tuple[2]\n",
    "            train_loss /= len(self.train_loader)\n",
    "            self.results['train_loss'].append(train_loss)\n",
    "            self.results['train_dice_score'].append(dice_score / len(self.train_loader))\n",
    "            self.results['train_f1_score'].append(f1_score / len(self.train_loader))\n",
    "            self.results['train_precision'].append(precision / len(self.train_loader))\n",
    "            self.results['train_recall'].append(recall / len(self.train_loader))\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Dice Score: {self.results[\"train_dice_score\"][-1]:.4f}, Train F1 score: {self.results[\"train_f1_score\"][-1]:.4f}')\n",
    "            if (epoch + 1) % self.hyperparameters['val_step'] == 0:\n",
    "                val_loss_for_epoch=self.validate(epoch)\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step(val_loss_for_epoch)\n",
    "            if self.best_val_loss > np.mean(self.results['val_loss'][-5:]):\n",
    "                break\n",
    "    \n",
    "    def train_step(self, image, label):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(image)\n",
    "        output = output[:, 0, :, :] # Select the first channel\n",
    "        output = output.unsqueeze(1) # Add a channel dimension\n",
    "        loss = self.criterion(output, label)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return output, loss.item()\n",
    "\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        val_dice_score = 0\n",
    "        val_precision = 0\n",
    "        val_recall = 0\n",
    "        val_f1_score = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                image = data['image'].float().to(DEVICE)\n",
    "                label = data['mask'].float().to(DEVICE)\n",
    "                label = label[:, 0, :, :] # Select the first channel\n",
    "                label = label.unsqueeze(1) # Add a channel dimension\n",
    "                output = self.model(image)\n",
    "                output = output[:, 0, :, :] # Select the first channel\n",
    "                output = output.unsqueeze(1)\n",
    "                loss = self.criterion(output, label)\n",
    "                val_loss += loss.item()\n",
    "                val_dice_score += calculate_dice_score(output, label)\n",
    "                tuple = calculate_f1_score(output, label)\n",
    "                val_f1_score += tuple[0]\n",
    "                val_precision += tuple[1]\n",
    "                val_recall += tuple[2]\n",
    "\n",
    "            val_loss /= len(self.val_loader)\n",
    "            val_dice_score /= len(self.val_loader)\n",
    "            self.results['val_loss'].append(val_loss)\n",
    "            self.results['val_dice_score'].append(val_dice_score)\n",
    "            self.results['val_f1_score'].append(val_f1_score/ len(self.val_loader))\n",
    "            self.results['val_precision'].append(val_precision/ len(self.val_loader))\n",
    "            self.results['val_recall'].append(val_recall/ len(self.val_loader))\n",
    "            print(f'\\n Validation Loss: {val_loss:.4f}, Validation Dice Score: {val_dice_score:.4f}, Validation f1 score: {self.results['val_f1_score'][-1]:.4f}')\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_seg = self.model.state_dict()\n",
    "                self.save_model()\n",
    "                print(f'Best model updated at epoch {epoch+1} with val loss: {val_loss:.4f}')\n",
    "                #Add early stopping criteria\n",
    "\n",
    "            return val_loss\n",
    "    \n",
    "    def save_model(self):\n",
    "        filename = f'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_{self.hyperparameters['model_name']}_resnet34_model_lr_{self.hyperparameters['learning_rate']}_batch_{self.hyperparameters['batch_size']}_fold_{self.hyperparameters['fold_number']}.pth'\n",
    "        torch.save(self.best_model_seg, filename)\n",
    "        print(f'Model saved to {filename}')\n",
    "\n",
    "\n",
    "\n",
    "# Add this option to your model_names list if you want to try multiple models\n",
    "model_names = ['Segformer']\n",
    "\n",
    "for name in model_names:\n",
    "    lr = 0.0001\n",
    "    for fold_number in range(3):\n",
    "        print(f'Training model {name} for fold {fold_number+1}...')\n",
    "        train_indices, val_indices = split[fold_number]\n",
    "        train, train_masks, training_labels, val, val_masks, val_labels = get_splitted_data(train_indices, val_indices)\n",
    "        train_dataset, val_dataset = get_datasets(train, train_masks, training_labels, val, val_masks, val_labels)\n",
    "        train_loader, val_loader = get_dataloader(train_dataset, val_dataset, BATCH_SIZE)     \n",
    "\n",
    "        if name == 'Segformer':\n",
    "            model = smp.Segformer(\n",
    "                encoder_name=\"resnet34\", \n",
    "                encoder_weights=\"imagenet\", \n",
    "                in_channels=3, \n",
    "                classes=1,\n",
    "            )\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        model.to(DEVICE)\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            model_name=name,\n",
    "            lr=lr,\n",
    "            fold_number=fold_number,\n",
    "        )\n",
    "        \n",
    "        trainer.train(num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_csv = pd.read_csv(test_csv_path)\n",
    "test_img_path = glob(os.path.join(test_path, 'images', '*.png'))\n",
    "test_img_path.sort()\n",
    "\n",
    "test_dataset = CustomDataset(test_img_path, None, test_data_csv, is_train=False, resize_dim=RESIZE_DIM)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Paths: ['/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth', '/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_1.pth', '/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_2.pth', '/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_3.pth', '/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_4.pth']\n",
      "Processing model: /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_0.pth\n",
      "Processing model: /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_1.pth\n",
      "Processing model: /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_2.pth\n",
      "Processing model: /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_3.pth\n",
      "Processing model: /home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34/best_seg_Segformer_resnet34_model_lr_0.0001_batch_4_fold_4.pth\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "# Path where the models are stored\n",
    "model_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34'\n",
    "model_paths = glob(os.path.join(model_path, 'best_seg_Segformer*.pth'))\n",
    "model_paths.sort()\n",
    "print(f'Model Paths: {model_paths}')\n",
    "\n",
    "# Load test CSV to maintain ID ordering\n",
    "test_csv_data = pd.read_csv(test_csv_path)\n",
    "test_csv_data = test_csv_data.sort_values(by='id')\n",
    "test_csv_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Initialize an empty tensor to accumulate predictions\n",
    "ensemble_preds = {}\n",
    "name = None\n",
    "# Loop through each model in the ensemble\n",
    "for model_file in model_paths:\n",
    "    print(f'Processing model: {model_file}')\n",
    "\n",
    "\n",
    "    if 'Segformer' in model_file:\n",
    "        name = 'Segformer'\n",
    "        model_unet = smp.Segformer(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=1)\n",
    "\n",
    "    model_instance = model_unet\n",
    "    model_instance.load_state_dict(torch.load(model_file))\n",
    "    model_instance.eval()\n",
    "    model_instance.to(DEVICE)\n",
    "    model_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images = data['image'].to(DEVICE)\n",
    "            ids = data['id']\n",
    "            outputs = model_instance(images)\n",
    "            # print(f'Output shape: {outputs.size()}')e\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            #convert to binary prediction\n",
    "\n",
    "            preds = (probs > 0.5).float().cpu()  # [B, 1, H, W]\n",
    "\n",
    "            for id_val, pred_mask in zip(ids, preds):\n",
    "                mask_np = pred_mask.squeeze().numpy()\n",
    "                model_preds.append((id_val, pred_mask.squeeze()))\n",
    "\n",
    "    # Sort predictions by ID\n",
    "    model_preds.sort(key=lambda x: x[0])\n",
    "    ids_sorted = [x[0] for x in model_preds]\n",
    "    preds_sorted = [x[1] for x in model_preds]\n",
    "    model_preds_tensor = torch.stack(preds_sorted)\n",
    "    for id in ids_sorted:\n",
    "        if id not in ensemble_preds:\n",
    "            ensemble_preds[id] = model_preds_tensor[ids_sorted.index(id)]\n",
    "        else:\n",
    "            ensemble_preds[id] += model_preds_tensor[ids_sorted.index(id)]\n",
    "\n",
    "# Average ensemble predictions\n",
    "for id in ensemble_preds:\n",
    "    ensemble_preds[id] /= len(model_paths)\n",
    "    # Convert to binary mask\n",
    "    ensemble_preds[id] = (ensemble_preds[id] > 0.5).float()\n",
    "\n",
    "ensemble_output_dir = os.path.join(model_path, f'submission_masks_{name}_mobilenet_v2')\n",
    "os.makedirs(ensemble_output_dir, exist_ok=True)\n",
    "\n",
    "for id_val, pred_mask in ensemble_preds.items():\n",
    "    # Convert single-channel mask to uint8 image\n",
    "    mask_np = (pred_mask.squeeze().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    mask_img = Image.fromarray(mask_np)\n",
    "    \n",
    "    mask_img.save(os.path.join(ensemble_output_dir,f\"{id_val}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following code generates the masktorle transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def mask2rle(img):\n",
    "    #https://www.kaggle.com/code/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "    #img: numpy array, 1 - mask, 0 - background\n",
    "    #Returns run length as string formated\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(256,256)):\n",
    "    #mask_rle: run-length as string formated (start length)\n",
    "    #shape: (width,height) of array to return \n",
    "    #Returns numpy array, 1 - mask, 0 - background\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "img_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/mobilenet_v2/submission_masks_Segformer_mobilenet_v2'\n",
    "submission_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/submission_class_resnet34.csv'\n",
    "submission_path_dir = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2'\n",
    "\n",
    "images = glob(os.path.join(img_path, '*.png'))\n",
    "\n",
    "encoding = []\n",
    "for image in images:\n",
    "    img = Image.open(image)\n",
    "    id = os.path.basename(image).split('/')[0]\n",
    "    # convert  to numpy array\n",
    "    img = np.array(img)\n",
    "    # print(f'img shape: {img.shape}')\n",
    "    encoding.append((id, mask2rle(img)))\n",
    "\n",
    "submission_path_df = pd.read_csv(submission_path)\n",
    "\n",
    "for id, seg_pred in encoding:\n",
    "    if seg_pred:\n",
    "        submission_path_df.loc[submission_path_df['id'] == id, 'segmentation_pred'] = seg_pred\n",
    "    else:\n",
    "        submission_path_df.loc[submission_path_df['id'] == id, 'segmentation_pred'] = 'Healthy'\n",
    "\n",
    "submission_path_df.to_csv(os.path.join(submission_path_dir,'submission_seg_DeepLabV3Plus_mobilenet_v2_class_resnet34.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
