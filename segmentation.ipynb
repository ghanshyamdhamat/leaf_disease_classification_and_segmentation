{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import skimage as ski\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from skimage import transform as ski_transform\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, RandomRotation\n",
    "from torchvision import models\n",
    "import torchvision.transforms.functional as FT\n",
    "from torcheval.metrics import functional as FM\n",
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    RandomRotation(10),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def joint_random_rotation(image, label, degrees):\n",
    "    # Get a random angle from the range [-degrees, degrees]\n",
    "    angle = RandomRotation.get_params([-degrees, degrees])\n",
    "    \n",
    "    # Rotate the image using bilinear interpolation\n",
    "    image = FT.rotate(image, angle, interpolation=Image.BILINEAR)\n",
    "    \n",
    "    # Rotate the label using nearest neighbor to avoid interpolating label values\n",
    "    label = FT.rotate(label, angle, interpolation=Image.NEAREST)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def joint_random_horizontal_flip(image, label):\n",
    "    if torch.rand(1) < 0.5:\n",
    "        image = FT.hflip(image)\n",
    "        label = FT.hflip(label)\n",
    "    return image, label\n",
    "\n",
    "def joint_random_vertical_flip(image, label):\n",
    "    if torch.rand(1) < 0.5:\n",
    "        image = FT.vflip(image)\n",
    "        label = FT.vflip(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def joint_random_crop(image, label, output_size):\n",
    "    # Get the size of the image\n",
    "    w, h = image.size\n",
    "\n",
    "    # Get the target size\n",
    "    th, tw = output_size\n",
    "\n",
    "    # Randomly crop the image\n",
    "    i = torch.randint(0, h - th + 1, (1,))\n",
    "    j = torch.randint(0, w - tw + 1, (1,))\n",
    "    image = FT.crop(image, i.item(), j.item(), th, tw)\n",
    "    \n",
    "    # Crop the label using the same parameters\n",
    "    label = FT.crop(label, i.item(), j.item(), th, tw)\n",
    "\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 60\n",
    "LEARNING_RATE = [0.0001]#,0.0001,0.00001]\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "RESIZE_DIM = (256, 256)\n",
    "repeats = 3\n",
    "val_step = 3 # Every 3 epoch carry out validation\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide training path and test_path\n",
    "train_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/Dataset/train'\n",
    "test_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/Dataset/test'\n",
    "\n",
    "train_csv_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/train.csv'\n",
    "test_csv_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/mlds_assignmet_2_ml_dl/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "id : Name of the image\n",
    "Binary prediction\n",
    "    Healthy = 0\n",
    "    Diseased = 1\n",
    "segmentation prediction\n",
    "    Probably the id of the diseased pixel\n",
    "\"\"\"\n",
    "train_csv_data = pd.read_csv(train_csv_path)\n",
    "#Sort train_csv_data by id\n",
    "train_csv_data = train_csv_data.sort_values(by='id')\n",
    "train_csv_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, masks, labels, is_train= True, resize_dim = (224, 224)):\n",
    "        self.resize_dim = resize_dim\n",
    "        self.images = images\n",
    "        self.is_train = is_train\n",
    "        self.image_transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.label_transform = ToTensor()\n",
    "        if is_train:\n",
    "            self.masks = masks\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            self.masks = None\n",
    "            self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.images):\n",
    "            print('Reduce the index count as it is greater than the length of the dataset')\n",
    "            return None\n",
    "        if idx < 0:\n",
    "            print('Index should be greater than or equal to 0')\n",
    "            return None\n",
    "        data = {}\n",
    "\n",
    "        if self.is_train:\n",
    "            data['image'] = Image.open(self.images[idx])\n",
    "            data['mask'] = Image.open(self.masks[idx])\n",
    "            data['class_label'] = self.labels.iloc[idx, 1]\n",
    "            data['id'] = self.images[idx].split('/')[-1]\n",
    "            data['image'], data['mask'] = joint_random_rotation(data['image'], data['mask'], 10)\n",
    "            data['image'], data['mask'] = joint_random_horizontal_flip(data['image'], data['mask'])\n",
    "            data['image'], data['mask'] = joint_random_vertical_flip(data['image'], data['mask'])\n",
    "            data['image'], data['mask'] = joint_random_crop(data['image'], data['mask'], self.resize_dim)\n",
    "            data['image'] = data['image'].resize(self.resize_dim)\n",
    "            data['mask'] = data['mask'].resize(self.resize_dim)\n",
    "            data['class_label'] = torch.tensor(data['class_label']).float()\n",
    "            if self.image_transform:\n",
    "                data['image'] = self.image_transform(data['image']) \n",
    "                data['mask'] = self.label_transform(data['mask'])\n",
    "            return data\n",
    "        else:\n",
    "            data['image'] = Image.open(self.images[idx])\n",
    "            data['id'] = self.images[idx].split('/')[-1]\n",
    "            if self.image_transform:\n",
    "                data['image'] = self.image_transform(data['image'])\n",
    "            return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the images in val and train from train_path\n",
    "def create_k_fold_split(train_path, train_csv_path):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    train_img_paths = glob(os.path.join(train_path, 'images', '*.png'))\n",
    "    train_img_paths.sort()\n",
    "    train_mask_paths = glob(os.path.join(train_path, 'masks', '*.png'))\n",
    "    train_mask_paths.sort() \n",
    "    train_labels = pd.read_csv(train_csv_path)\n",
    "    train_labels = train_labels.sort_values(by='id')\n",
    "    train_labels.index = range(len(train_labels))\n",
    "    split = list(kf.split(train_img_paths))\n",
    "    return split, train_img_paths, train_mask_paths, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(train_img_paths, train_mask_paths, train_labels, val_img_paths, val_mask_paths, val_labels):\n",
    "    train_dataset = CustomDataset(train_img_paths, train_mask_paths, train_labels, is_train=True, resize_dim=RESIZE_DIM)\n",
    "    val_dataset = CustomDataset(val_img_paths, val_mask_paths, val_labels, is_train=True, resize_dim=RESIZE_DIM)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def get_dataloader(train_dataset, val_dataset, batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def get_splitted_data(train_indices, val_indices):\n",
    "    train = [train_img_paths[i] for i in train_indices]\n",
    "    train_masks = [train_mask_paths[i] for i in train_indices]\n",
    "    training_labels = train_labels.iloc[train_indices]\n",
    "    val = [train_img_paths[i] for i in val_indices]\n",
    "    val_masks = [train_mask_paths[i] for i in val_indices]\n",
    "    val_labels = train_labels.iloc[val_indices]\n",
    "    return train, train_masks, training_labels, val, val_masks, val_labels\n",
    "\n",
    "split, train_img_paths, train_mask_paths, train_labels = create_k_fold_split(train_path, train_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_dice_score(preds, targets):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        preds: Binary prediction mask (B, C, H, W)\n",
    "        targets: Binary target mask (B, C, H, W)\n",
    "    Returns:\n",
    "        Mean Dice score across batch and channels\n",
    "    \"\"\"\n",
    "    dices = []\n",
    "    smooth = 1e-6\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > 0.5).float()\n",
    "    for i in range(targets.size(0)):\n",
    "        pred_flat = preds[i].reshape(-1)\n",
    "        target_flat = targets[i,0].reshape(-1)\n",
    "        intersection = torch.sum(pred_flat * target_flat)\n",
    "        if torch.sum(pred_flat) == 0 and torch.sum(target_flat) == 0:\n",
    "            dices.append(1.0)\n",
    "        elif torch.sum(pred_flat) == 0 or torch.sum(target_flat) == 0:\n",
    "            dices.append(0.0)\n",
    "        else:\n",
    "            dices.append((2. * intersection + smooth) / (torch.sum(pred_flat) + torch.sum(target_flat) + smooth))\n",
    "    return torch.mean(torch.tensor(dices)).item()\n",
    "\n",
    "def calculate_f1_score(preds, targets):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        preds: Binary prediction mask (B, C, H, W)\n",
    "        targets: Binary target mask (B, C, H, W)\n",
    "    Returns:\n",
    "        Mean accuracy across batch and channels\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > 0.5).float()\n",
    "    preds = preds.reshape(-1)\n",
    "    targets = targets.reshape(-1)\n",
    "    tp = torch.sum(preds * targets)\n",
    "    fp = torch.sum(preds) - tp\n",
    "    fn = torch.sum(targets) - tp\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    return f1_score.item(), precision.item(), recall.item()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler=None, model_name=None,lr = 0.001, fold_number=None):\n",
    "\n",
    "        self.scheduler = scheduler\n",
    "        self.hyperparameters = {\n",
    "            'model_name': model_name,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': lr,\n",
    "            'epochs': EPOCHS,\n",
    "            'val_step': val_step,\n",
    "            'seed': seed,\n",
    "            'fold_number': fold_number,\n",
    "        }\n",
    "        self.model = model\n",
    "        self.criterion = smp.losses.DiceLoss(mode='binary', from_logits=True , smooth=1e-7)\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.best_model_seg = None\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.results = {\n",
    "            'train_loss': [],\n",
    "            'train_dice_score': [],\n",
    "            'train_precision': [],\n",
    "            'train_recall': [],\n",
    "            'train_f1_score': [],\n",
    "            'val_loss': [],\n",
    "            'val_dice_score': [],\n",
    "            'val_f1_score': [],\n",
    "            'val_precision': [],\n",
    "            'val_recall': [],\n",
    "        }\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            output_seg = None\n",
    "            dice_score = 0\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            f1_score = 0\n",
    "            val_loss_for_epoch = 0\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "                image = data['image'].float().to(DEVICE)\n",
    "                label = data['mask'].float().to(DEVICE)\n",
    "                label = label[:, 0, :, :] # Select the first channel\n",
    "                label = label.unsqueeze(1) # Add a channel dimension\n",
    "                output_seg, loss = self.train_step(image, label) \n",
    "                output_seg = output_seg[:, 0, :, :] # Select the first channel\n",
    "                output_seg = output_seg.unsqueeze(1) # Add a channel dimension     \n",
    "                train_loss += loss\n",
    "                dice_score += calculate_dice_score(output_seg, label)\n",
    "                tuple = calculate_f1_score(output_seg, label)\n",
    "                f1_score += tuple[0]\n",
    "                precision += tuple[1]\n",
    "                recall += tuple[2]\n",
    "            train_loss /= len(self.train_loader)\n",
    "            self.results['train_loss'].append(train_loss)\n",
    "            self.results['train_dice_score'].append(dice_score / len(self.train_loader))\n",
    "            self.results['train_f1_score'].append(f1_score / len(self.train_loader))\n",
    "            self.results['train_precision'].append(precision / len(self.train_loader))\n",
    "            self.results['train_recall'].append(recall / len(self.train_loader))\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Dice Score: {self.results[\"train_dice_score\"][-1]:.4f}, Train F1 score: {self.results[\"train_f1_score\"][-1]:.4f}')\n",
    "            if (epoch + 1) % self.hyperparameters['val_step'] == 0:\n",
    "                val_loss_for_epoch=self.validate(epoch)\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step(val_loss_for_epoch)\n",
    "            if self.best_val_loss > np.mean(self.results['val_loss'][-5:]):\n",
    "                break\n",
    "    \n",
    "    def train_step(self, image, label):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(image)\n",
    "        output = output[:, 0, :, :] # Select the first channel\n",
    "        output = output.unsqueeze(1) # Add a channel dimension\n",
    "        loss = self.criterion(output, label)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return output, loss.item()\n",
    "\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        val_dice_score = 0\n",
    "        val_precision = 0\n",
    "        val_recall = 0\n",
    "        val_f1_score = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                image = data['image'].float().to(DEVICE)\n",
    "                label = data['mask'].float().to(DEVICE)\n",
    "                label = label[:, 0, :, :] # Select the first channel\n",
    "                label = label.unsqueeze(1) # Add a channel dimension\n",
    "                output = self.model(image)\n",
    "                output = output[:, 0, :, :] # Select the first channel\n",
    "                output = output.unsqueeze(1)\n",
    "                loss = self.criterion(output, label)\n",
    "                val_loss += loss.item()\n",
    "                val_dice_score += calculate_dice_score(output, label)\n",
    "                tuple = calculate_f1_score(output, label)\n",
    "                val_f1_score += tuple[0]\n",
    "                val_precision += tuple[1]\n",
    "                val_recall += tuple[2]\n",
    "\n",
    "            val_loss /= len(self.val_loader)\n",
    "            val_dice_score /= len(self.val_loader)\n",
    "            self.results['val_loss'].append(val_loss)\n",
    "            self.results['val_dice_score'].append(val_dice_score)\n",
    "            self.results['val_f1_score'].append(val_f1_score/ len(self.val_loader))\n",
    "            self.results['val_precision'].append(val_precision/ len(self.val_loader))\n",
    "            self.results['val_recall'].append(val_recall/ len(self.val_loader))\n",
    "            print(f'\\n Validation Loss: {val_loss:.4f}, Validation Dice Score: {val_dice_score:.4f}, Validation f1 score: {self.results['val_f1_score'][-1]:.4f}')\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_seg = self.model.state_dict()\n",
    "                self.save_model()\n",
    "                print(f'Best model updated at epoch {epoch+1} with val loss: {val_loss:.4f}')\n",
    "                #Add early stopping criteria\n",
    "\n",
    "            return val_loss\n",
    "    \n",
    "    def save_model(self):\n",
    "        filename = f'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/best_seg_{self.hyperparameters['model_name']}_resnet34_model_lr_{self.hyperparameters['learning_rate']}_batch_{self.hyperparameters['batch_size']}_fold_{self.hyperparameters['fold_number']}.pth'\n",
    "        torch.save(self.best_model_seg, filename)\n",
    "        print(f'Model saved to {filename}')\n",
    "\n",
    "\n",
    "\n",
    "# Add this option to your model_names list if you want to try multiple models\n",
    "model_names = ['Segformer']\n",
    "\n",
    "for name in model_names:\n",
    "    lr = 0.0001\n",
    "    for fold_number in range(3):\n",
    "        print(f'Training model {name} for fold {fold_number+1}...')\n",
    "        train_indices, val_indices = split[fold_number]\n",
    "        train, train_masks, training_labels, val, val_masks, val_labels = get_splitted_data(train_indices, val_indices)\n",
    "        train_dataset, val_dataset = get_datasets(train, train_masks, training_labels, val, val_masks, val_labels)\n",
    "        train_loader, val_loader = get_dataloader(train_dataset, val_dataset, BATCH_SIZE)     \n",
    "\n",
    "        if name == 'Segformer':\n",
    "            model = smp.Segformer(\n",
    "                encoder_name=\"resnet34\", \n",
    "                encoder_weights=\"imagenet\", \n",
    "                in_channels=3, \n",
    "                classes=1,\n",
    "            )\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        model.to(DEVICE)\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            model_name=name,\n",
    "            lr=lr,\n",
    "            fold_number=fold_number,\n",
    "        )\n",
    "        \n",
    "        trainer.train(num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_csv = pd.read_csv(test_csv_path)\n",
    "test_img_path = glob(os.path.join(test_path, 'images', '*.png'))\n",
    "test_img_path.sort()\n",
    "\n",
    "test_dataset = CustomDataset(test_img_path, None, test_data_csv, is_train=False, resize_dim=RESIZE_DIM)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "# Path where the models are stored\n",
    "model_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/res34'\n",
    "model_paths = glob(os.path.join(model_path, 'best_seg_Segformer*.pth'))\n",
    "model_paths.sort()\n",
    "print(f'Model Paths: {model_paths}')\n",
    "\n",
    "# Load test CSV to maintain ID ordering\n",
    "test_csv_data = pd.read_csv(test_csv_path)\n",
    "test_csv_data = test_csv_data.sort_values(by='id')\n",
    "test_csv_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Initialize an empty tensor to accumulate predictions\n",
    "ensemble_preds = {}\n",
    "name = None\n",
    "# Loop through each model in the ensemble\n",
    "for model_file in model_paths:\n",
    "    print(f'Processing model: {model_file}')\n",
    "\n",
    "\n",
    "    if 'Segformer' in model_file:\n",
    "        name = 'Segformer'\n",
    "        model_unet = smp.Segformer(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=1)\n",
    "\n",
    "    model_instance = model_unet\n",
    "    model_instance.load_state_dict(torch.load(model_file))\n",
    "    model_instance.eval()\n",
    "    model_instance.to(DEVICE)\n",
    "    model_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images = data['image'].to(DEVICE)\n",
    "            ids = data['id']\n",
    "            outputs = model_instance(images)\n",
    "            # print(f'Output shape: {outputs.size()}')e\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            #convert to binary prediction\n",
    "\n",
    "            preds = (probs > 0.5).float().cpu()  # [B, 1, H, W]\n",
    "\n",
    "            for id_val, pred_mask in zip(ids, preds):\n",
    "                mask_np = pred_mask.squeeze().numpy()\n",
    "                model_preds.append((id_val, pred_mask.squeeze()))\n",
    "\n",
    "    # Sort predictions by ID\n",
    "    model_preds.sort(key=lambda x: x[0])\n",
    "    ids_sorted = [x[0] for x in model_preds]\n",
    "    preds_sorted = [x[1] for x in model_preds]\n",
    "    model_preds_tensor = torch.stack(preds_sorted)\n",
    "    for id in ids_sorted:\n",
    "        if id not in ensemble_preds:\n",
    "            ensemble_preds[id] = model_preds_tensor[ids_sorted.index(id)]\n",
    "        else:\n",
    "            ensemble_preds[id] += model_preds_tensor[ids_sorted.index(id)]\n",
    "\n",
    "# Average ensemble predictions\n",
    "for id in ensemble_preds:\n",
    "    ensemble_preds[id] /= len(model_paths)\n",
    "    # Convert to binary mask\n",
    "    ensemble_preds[id] = (ensemble_preds[id] > 0.5).float()\n",
    "\n",
    "ensemble_output_dir = os.path.join(model_path, f'submission_masks_{name}_mobilenet_v2')\n",
    "os.makedirs(ensemble_output_dir, exist_ok=True)\n",
    "\n",
    "for id_val, pred_mask in ensemble_preds.items():\n",
    "    # Convert single-channel mask to uint8 image\n",
    "    mask_np = (pred_mask.squeeze().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    mask_img = Image.fromarray(mask_np)\n",
    "    \n",
    "    mask_img.save(os.path.join(ensemble_output_dir,f\"{id_val}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following code generates the masktorle transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def mask2rle(img):\n",
    "    #https://www.kaggle.com/code/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "    #img: numpy array, 1 - mask, 0 - background\n",
    "    #Returns run length as string formated\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(256,256)):\n",
    "    #mask_rle: run-length as string formated (start length)\n",
    "    #shape: (width,height) of array to return \n",
    "    #Returns numpy array, 1 - mask, 0 - background\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "img_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/models/mobilenet_v2/submission_masks_Segformer_mobilenet_v2'\n",
    "submission_path = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2/submission_class_resnet34.csv'\n",
    "submission_path_dir = r'/home/biomedialab/Desktop/Codes/Assignments/MLDS/Assignment_2/Q2'\n",
    "\n",
    "images = glob(os.path.join(img_path, '*.png'))\n",
    "\n",
    "encoding = []\n",
    "for image in images:\n",
    "    img = Image.open(image)\n",
    "    id = os.path.basename(image).split('/')[0]\n",
    "    # convert  to numpy array\n",
    "    img = np.array(img)\n",
    "    # print(f'img shape: {img.shape}')\n",
    "    encoding.append((id, mask2rle(img)))\n",
    "\n",
    "submission_path_df = pd.read_csv(submission_path)\n",
    "\n",
    "for id, seg_pred in encoding:\n",
    "    if seg_pred:\n",
    "        submission_path_df.loc[submission_path_df['id'] == id, 'segmentation_pred'] = seg_pred\n",
    "    else:\n",
    "        submission_path_df.loc[submission_path_df['id'] == id, 'segmentation_pred'] = 'Healthy'\n",
    "\n",
    "submission_path_df.to_csv(os.path.join(submission_path_dir,'submission_seg_DeepLabV3Plus_mobilenet_v2_class_resnet34.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
